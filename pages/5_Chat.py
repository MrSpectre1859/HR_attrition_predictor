import streamlit as st
from openai import OpenAI, APIError, APIConnectionError, RateLimitError
from utils import *
from dotenv import load_dotenv
import os

load_dotenv(override=True)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

model = load_model()
df_original, df_prep = load_data()
explainer = get_explainer(model, df_prep)

def page_chat(df_original, df_prep, model):
    if "shap_values_class1" not in st.session_state:
        with st.status("‚è≥ Carregando SHAP...\n\nIsso costuma levar no m√°ximo 1 minuto.", expanded=True) as status:
            shap_values_class1 = compute_shap_values(explainer, df_prep)
            st.session_state.shap_values_class1 = shap_values_class1
            status.update(label="‚úÖ SHAP carregado com sucesso.", state="complete")
    else:
        shap_values_class1 = st.session_state.shap_values_class1

    st.title("üí¨ Converse com a IA do RH")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = [{"role": "system", 
        "content": ("Voc√™ √© um profissional especialista em People Analytics e Recursos Humanos, com mais de 30 anos de experi√™ncia "
    "em empresas de grande porte nacionais e multinacionais. Seu papel √© analisar dados de funcion√°rios de forma √©tica, "
    "estrat√©gica e baseada em evid√™ncias, trazendo recomenda√ß√µes e reflex√µes √∫teis para gestores de RH e lideran√ßas. \n\n"
    "Responda sempre de maneira emp√°tica, clara e profissional, utilizando termos de RH com explica√ß√µes acess√≠veis quando necess√°rio. "
    "Evite suposi√ß√µes sem base nos dados fornecidos. Caso precise, pe√ßa mais informa√ß√µes ao usu√°rio. "
    "Voc√™ deve ajudar a interpretar m√©tricas de turnover, engajamento, satisfa√ß√£o, tempo de empresa, entre outros. "
    "Sua comunica√ß√£o deve transmitir confian√ßa, autoridade e colabora√ß√£o, como um verdadeiro parceiro estrat√©gico do neg√≥cio.")}]

    funcionario_idx = st.selectbox("Selecione um funcion√°rio", list(range(len(df_original))))
    funcionario_info = df_original.iloc[funcionario_idx].to_dict()

    funcionario_prep = df_prep.iloc[funcionario_idx:funcionario_idx+1].drop(columns="Attrition_numerical")
    risk_score = model.predict_proba(funcionario_prep)[:, 1][0]
    risk_level = classify_risk(risk_score)
    fatores_importantes = shap_func_id(shap_values_class1, df_prep, funcionario_idx)

    resultados_modelo = (
        f"- Probabilidade de sa√≠da: {risk_score:.2%}\n"
        f"- Classifica√ß√£o de risco: {risk_level}\n\n"
        f"Principais fatores que influenciam essa previs√£o:\n"
        f"1) {fatores_importantes[0]}\n"
        f"2) {fatores_importantes[1]}\n"
        f"3) {fatores_importantes[2]}\n"
    )

    user_message = st.text_area("Digite sua pergunta:")

    if st.button("Enviar"):
        if user_message.strip():
            # Adiciona ao hist√≥rico apenas a pergunta do usu√°rio para exibi√ß√£o
            st.session_state.chat_history.append({"role": "user", "content": user_message})

            # Constr√≥i o contexto com os dados + pergunta, mas sem mostrar isso pro usu√°rio
            mensagem_contextualizada = f"Os dados do funcion√°rio s√£o:\n{funcionario_info}\n\n" \
                                    f"Seguem os dados da previs√£o do modelo e explica√ß√£o SHAP:\n{resultados_modelo}\n" \
                                    f"Pergunta do usu√°rio: {user_message}"

            # Envia ao modelo com o hist√≥rico anterior e a mensagem contextualizada
            mensagens_envio = st.session_state.chat_history[:-1] + [{"role": "user", "content": mensagem_contextualizada}]

            try:
                resposta = client.chat.completions.create(
                    model="gpt-4o-mini-2024-07-18",
                    messages=mensagens_envio,
                    temperature=1,
                    max_tokens=2048,
                    top_p=1
                )

                resposta_texto = resposta.choices[0].message.content
                st.session_state.chat_history.append({"role": "assistant", "content": resposta_texto})

            except APIError as e:
                st.error(f"Erro da API OpenAI: {e}")
            except APIConnectionError as e:
                st.error(f"Erro de conex√£o com a OpenAI: {e}")
            except RateLimitError as e:
                st.error(f"Limite de requisi√ß√µes excedido: {e}")

    for mensagem in st.session_state.chat_history:
        if mensagem["role"]  == "system":
            continue
        with st.chat_message(mensagem["role"]):
            st.write(mensagem["content"])

    if st.button("Resetar Chat"):
        st.session_state.chat_history = [{"role": "system", "content": "Como posso te ajudar hoje?"}]
        st.rerun()

page_chat(df_original, df_prep, model)
